---
title: "code"
author: "Marjorie Blanco"
date: "10/2/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
```

```{r}
signs <- read_csv("~/GitHub/datacamp/SL Classification/knn_traffic_signs.csv")


# Load the 'class' package
library(class)

next_sign <- signs[1, -c(1:3)]
# Create a vector of labels
sign_types <- signs$sign_type

# Classify the next sign observed
#knn(train = signs[-1], test = next_sign, cl = sign_types)

# Examine the structure of the signs dataset
str(signs)

# Count the number of signs of each type
table(signs$sign_type)

# Check r10's average red level by sign type
aggregate(r10 ~ sign_type, data = signs, mean)

# Use kNN to identify the test road signs
sign_types <- signs$sign_type
#signs_pred <- knn(train = signs[-1], test = test_signs[-1], cl = sign_types)

# Create a confusion matrix of the actual versus predicted values
#signs_actual <- test_signs$sign_type
#table(signs_pred, signs_actual)

# Compute the accuracy
#mean(signs_actual == signs_pred)
```

```{r}
locations <- read_csv("~/GitHub/datacamp/SL Classification/locations.csv")
where9am <- locations[locations$hour == 9, c("daytype","location") ]

# Compute P(A) 
p_A <- nrow(subset(where9am, location ==  "office")) / nrow(where9am)

# Compute P(B)
p_B <- nrow(subset(where9am, daytype ==  "weekday")) / nrow(where9am)

# Compute the observed P(A and B)
p_AB <- nrow(subset(where9am, daytype ==  "weekday" & location ==  "office")) / nrow(where9am)

# Compute P(A | B) and print its value
p_A_given_B <- p_AB /p_B
p_A_given_B


# Load the naivebayes package
library(naivebayes)

thursday9am <- data.frame(daytype = c("weekday") )
saturday9am <- data.frame(daytype = c("weekend") )

# Build the location prediction model
locmodel <- naive_bayes(location ~ daytype, data = where9am)

# Predict Thursday's 9am location
predict(locmodel,newdata = thursday9am)

# Predict Saturdays's 9am location
predict(locmodel,newdata = saturday9am)

# The 'naivebayes' package is loaded into the workspace
# and the Naive Bayes 'locmodel' has been built

# Examine the location prediction model
locmodel

# Obtain the predicted probabilities for Thursday at 9am
predict(locmodel, thursday9am , type = "prob")

# Obtain the predicted probabilities for Saturday at 9am
predict(locmodel, saturday9am , type = "prob")


# The 'naivebayes' package is loaded into the workspace already

# Build a NB model of location
locmodel <-  naive_bayes(location ~ daytype + hourtype, data = locations)

weekday_afternoon <- data.frame(  daytype = c("weekday") , hourtype = c("afternoon"), location = c("office"))

weekday_evening <- data.frame(  daytype = c("weekday") , hourtype = c("evening"), location = c("home"))

# Predict Brett's location on a weekday afternoon
predict(locmodel,newdata = weekday_afternoon)

# Predict Brett's location on a weekday evening
predict(locmodel,newdata = weekday_evening)

# The 'naivebayes' package is loaded into the workspace already
# The Naive Bayes location model (locmodel) has already been built


weekend_afternoon <- data.frame(  daytype = c("weekend") , hourtype = c("afternoon"), location = c("home"))

# Observe the predicted probabilities for a weekend afternoon
predict(locmodel, newdata = weekend_afternoon, type = "prob")


# Build a new model using the Laplace correction
locmodel2 <- naive_bayes(location ~ daytype + hourtype, data = locations, laplace =1)

# Observe the new predicted probabilities for a weekend afternoon
predict(locmodel2, newdata = weekend_afternoon, type = "prob")
```

```{r}
donors <- read_csv("~/GitHub/datacamp/SL Classification/donors.csv")

# Examine the dataset to identify potential independent variables
str(donors)

# Explore the dependent variable
table(donors$donated)

# Build the donation model
donation_model <- glm(donated ~ bad_address + interest_religion + interest_veterans,  
                      data = donors, family = "binomial")

# Summarize the model results
summary(donation_model)

# Load the pROC package
library(pROC) 

# Create a ROC curve
ROC <- roc(donors$donated, donors$donation_prob)

# Plot the ROC curve
plot(ROC, col = "blue")

# Calculate the area under the curve (AUC)
auc(ROC)


# Convert the wealth rating to a factor
donors$wealth_rating <- factor(donors$wealth_rating, levels = c(0, 1, 2, 3), labels = c("Unknown", "Low", "Medium", "High"))

# Use relevel() to change reference category
donors$wealth_rating <- relevel(donors$wealth_rating, ref = "Medium")

# See how our factor coding impacts the model
summary(glm(donated ~ wealth_rating, data = donors, family = "binomial"))


# Find the average age among non-missing values
summary(donors$age)

# Impute missing age values with mean(age)
donors$imputed_age <- ifelse(is.na(donors$age), 61.65, donors$age)

# Create missing value indicator for age
donors$missing_age <- ifelse(is.na(donors$age), 1, 0)

# Build a recency, frequency, and money (RFM) model
rfm_model <- glm(donated ~ money + recency * frequency,  
                      data = donors, family = "binomial")

# Summarize the RFM model to see how the parameters were coded
summary(rfm_model)

# Compute predicted probabilities for the RFM model
rfm_prob <- predict(rfm_model, type = "response")

# Plot the ROC curve and find AUC for the new model
library(pROC)
ROC <- roc(donors$donated, rfm_prob)
plot(ROC, col = "red")
auc(ROC)

# Specify a null model with no predictors
null_model <- glm(donated  ~ 1, data = donors, family = "binomial")

# Specify the full model using all of the potential predictors
full_model <- glm(donated  ~ ., data = donors, family = "binomial")

# Use a forward stepwise algorithm to build a parsimonious model
step_model <- step(null_model, scope = list(lower = null_model, upper = full_model), direction = "forward")

# Estimate the stepwise donation probability
step_prob <- predict(step_model, type = "response")

# Plot the ROC of the stepwise model
library(pROC)
ROC <- roc(donors$donated, step_prob)
plot(ROC, col = "red")
auc(ROC)

loans <- read_csv("~/GitHub/datacamp/SL Classification/loans.csv")
# Load the rpart package
library(rpart)

# Build a lending model predicting loan outcome versus loan amount and credit score
#loan_model <- rpart(outcome ~ loan_amount + credit_score, data = ___, method = "___", control = rpart.control(cp = 0))

# > good_credit
#   loan_amount emp_length home_ownership income   loan_purpose debt_to_income
# 1         LOW  10+ years       MORTGAGE   HIGH major_purchase        AVERAGE
#   credit_score recent_inquiry delinquent credit_accounts bad_public_record
# 1         HIGH             NO      NEVER            MANY                NO
#   credit_utilization past_bankrupt outcome
# 1                LOW            NO  repaid

# > bad_credit
#   loan_amount  emp_length home_ownership income loan_purpose debt_to_income
# 1         LOW 6 - 9 years           RENT MEDIUM          car            LOW
#   credit_score recent_inquiry delinquent credit_accounts bad_public_record
# 1          LOW            YES      NEVER             FEW                NO
#   credit_utilization past_bankrupt outcome
# 1               HIGH            NO  repaid

# Load the rpart package
library(rpart)

# Build a lending model predicting loan outcome versus loan amount and credit score
loan_model <- rpart(outcome ~ loan_amount + credit_score, data = loans, method = "class", control = rpart.control(cp = 0))

good_credit <- 
bad_credit <- 
  
# Make a prediction for someone with good credit
predict(loan_model, good_credit, type = "class")

# Make a prediction for someone with bad credit
predict(loan_model, bad_credit, type = "class")
```

```{r}
# Determine the number of rows for training
nrow(loans) * 0.75

# Create a random sample of row IDs
sample_rows <- sample(11312, 8484)

# Create the training dataset
loans_train <- loans[sample_rows, ]

# Create the test dataset
loans_test <- loans[-sample_rows, ]
```

